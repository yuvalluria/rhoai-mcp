OPIK OBSERVABILITY INTEGRATION (design)

1) How Opik observability can help
---------------------------------
- Traces: Opik records LLM calls, tool usage, agent flows (trace -> spans).
- MCP tool calls (run_prompt_evaluation, run_prompt_optimization, get_deployment_recommendation) are outbound HTTP; today we do not send these to Opik.
- If we send them as traces: every eval/optimize/recommend in Claude Code (or any MCP client) shows up in Opik. You get:
  * Latency and errors per tool call
  * Which prompts were evaluated/optimized and their scores
  * Cost/latency over time for recommendation and optimization
- Opik can then: create datasets from traces, run guardrails on traces, compare prompt versions (A/B), monitor regressions.

2) Two integration directions
-----------------------------
A) MCP as trace source (agent sends to Opik)
   - In rhoai-mcp: when run_prompt_evaluation / run_prompt_optimization / get_deployment_recommendation succeed, optionally create a trace in Opik (via Opik REST API or Python SDK).
   - Trace name e.g. "mcp_run_prompt_evaluation"; input = { prompt_text, dataset_path, ... }; output = { score_100, count, ... }; metadata = model, latency.
   - Requires: OPIK_API_KEY (or OPIK_URL + auth) in MCP server env; Opik backend reachable from cluster (Opik Cloud or self-hosted).
   - Benefit: one place to see all MCP-driven evals/optimizations; use Opik dashboards and “create dataset from traces” for follow-up optimization.

B) Opik as an MCP tool (agent asks Opik)
   - New tool(s), e.g. get_opik_trace_summary(project_name, since_minutes), list_opik_projects(), create_dataset_from_opik_traces(project_name, trace_ids).
   - Agent can answer: “What’s the quality and cost of our chatbot prompts in Opik last week?” or “Create an eval dataset from last 100 support traces.”
   - Requires: Opik API client in rhoai-mcp (REST or SDK), config (OPIK_API_URL, OPIK_API_KEY) in ConfigMap/Secret.
   - Benefit: Claude Code (or any MCP client) can query observability and create datasets without leaving the chat.

3) Cluster deployment and Opik
------------------------------
- Deploy rhoai-mcp as in deployment.yaml. Set RHOAI_MCP_OPIK_SERVICE_URL to your NeuralNav backend so recommendation/prompt tools work.
- For (A): add env OPIK_API_KEY (or OPIK_URL + OPIK_API_KEY) to the Deployment (from Secret). In neuralnav/prompt_optimization tools, after a successful HTTP response, call Opik API to create trace.
- For (B): add new domain opik_observability with tools that call Opik API; add OPIK_API_URL and OPIK_API_KEY to ConfigMap/Secret; register plugin in registry.py.

4) Minimal first step (A)
-------------------------
- Add optional dependency: opik (or httpx-only to Opik REST).
- In run_prompt_evaluation and run_prompt_optimization (and optionally get_deployment_recommendation): if OPIK_API_KEY set, POST to Opik traces API (or use opik.trace()) with name, input, output, metadata.
- No new MCP tools; existing tools become trace sources. Then use Opik UI to view and create datasets from those traces.
